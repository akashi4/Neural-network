{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../names.txt').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s: i+1 for i, s in enumerate(sorted(set(''.join(words))))}\n",
    "stoi['.'] = 0\n",
    "itos = {s: i for i, s in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-1.1136764 , -0.30688876],\n",
       "       [ 0.5948322 , -0.1667712 ]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_global_generator(42)\n",
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "a = tf.Variable(tf.random.normal((2, 3)), name='a')\n",
    "a@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([182339, 3]), TensorShape([22858, 3]), TensorShape([22949, 3]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def build_dataset(words: list[str]):\n",
    "    X, Y = [], []\n",
    "    context_size = 3\n",
    "    for w in words:\n",
    "        context = [0] * context_size\n",
    "        for ch in w + \".\":\n",
    "            X.append(context)\n",
    "            Y.append(stoi[ch])\n",
    "            # output = [itos[i] for i in context]\n",
    "            # print(f\"{''.join(output)} ----> {ch}\")\n",
    "            context = context[1:] + [stoi[ch]]\n",
    "    return tf.Variable(X), tf.Variable(Y)\n",
    "\n",
    "\n",
    "n1, n2 = int(0.8 * len(words)), int(0.9 * len(words))\n",
    "random.shuffle(words)\n",
    "\n",
    "X_train, Y_train = build_dataset(words=words[:n1])\n",
    "X_dev, Y_dev = build_dataset(words=words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words=words[n2:])\n",
    "\n",
    "# X_train, Y_train = X_train.to(device=device), Y_train.to(device=device)\n",
    "# X_dev, Y_dev = X_dev.to(device=device), Y_dev.to(device=device)\n",
    "# X_test, Y_test = X_test.to(device=device), Y_test.to(device=device)\n",
    "\n",
    "X_train.shape, X_dev.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = tf.Variable(tf.random.uniform(shape=(27, 5)), trainable=True)\n",
    "W1 = tf.Variable(tf.random.uniform(shape=(15, 200)), trainable=True)\n",
    "b1 = tf.Variable(tf.random.uniform(shape=(200,)), trainable=True)\n",
    "W2 = tf.Variable(tf.random.uniform(shape=(200, 27)), trainable=True)\n",
    "b2 = tf.Variable(tf.random.uniform(shape=(27,)), trainable=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
       "array([[0.35408378, 0.20130026, 0.5752524 , 0.20098436, 0.72094214,\n",
       "        0.35408378, 0.20130026, 0.5752524 , 0.20098436, 0.72094214,\n",
       "        0.35408378, 0.20130026, 0.5752524 , 0.20098436, 0.72094214]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = tf.gather(C, X_train)\n",
    "tf.reshape(ll[0], shape=(-1, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8762>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tf.size(p) for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward(inputs):\n",
    "    emb = tf.gather(C, inputs)\n",
    "    h = tf.tanh(tf.reshape(emb, shape=(-1, 3*5) @ W1+b1))\n",
    "    logits = h@W2+b2\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5)\n"
     ]
    }
   ],
   "source": [
    "stepi, lossi, lossd = [], [], []\n",
    "ix = tf.random.uniform(shape=(32,), minval=0, maxval=5, dtype=tf.int32)\n",
    "print(tf.gather(C, ix).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.CategoricalCrossentropy\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # minibatch\n",
    "    ix = tf.random.uniform(shape=(32,), minval=0, maxval=5, dtype=tf.int32)\n",
    "\n",
    "    inputs = tf.gather(X_train, ix)\n",
    "    targets = tf.gatehr(Y_train, ix)\n",
    "    logits = forward(inputs)\n",
    "    loss_train = cross_entropy(targets, logits)\n",
    "\n",
    "    logits_dev = forward(X_dev)\n",
    "    loss_dev = cross_entropy(X_dev, logits_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
